import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from scipy import stats
from sklearn.ensemble import IsolationForest
from sklearn.covariance import EllipticEnvelope
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
import pickle
import json
import io
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–∏–≥–º–∞-—Ñ–∞–∑—ã",
    page_icon="üî¨",
    layout="wide"
)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üî¨ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–∏–Ω–µ—Ç–∏–∫–∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Å–∏–≥–º–∞-—Ñ–∞–∑—ã –≤ —Å—Ç–∞–ª–∏ 12–•18–ù12–¢")
st.markdown("""
### –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é —Å–∏–≥–º–∞-—Ñ–∞–∑—ã, –≤—Ä–µ–º–µ–Ω–∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏ –∏ –Ω–æ–º–µ—Ä—É –∑–µ—Ä–Ω–∞
""")

class DataValidator:
    """–ö–ª–∞—Å—Å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
    
    @staticmethod
    def normalize_column_names(df):
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É"""
        column_mapping = {
            '–ù–æ–º–µ—Ä_–∑–µ—Ä–Ω–∞': 'G', '–ù–æ–º–µ—Ä –∑–µ—Ä–Ω–∞': 'G', '–ó–µ—Ä–Ω–æ': 'G',
            '–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞': 'T', '–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞_C': 'T', '–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ ¬∞C': 'T',
            '–í—Ä–µ–º—è': 't', '–í—Ä–µ–º—è_—á': 't', '–í—Ä–µ–º—è, —á': 't',
            '–°–∏–≥–º–∞_—Ñ–∞–∑–∞': 'f_exp (%)', '–°–∏–≥–º–∞-—Ñ–∞–∑–∞': 'f_exp (%)', 
            '–°–∏–≥–º–∞_—Ñ–∞–∑–∞_%': 'f_exp (%)', '–°–∏–≥–º–∞ —Ñ–∞–∑–∞': 'f_exp (%)',
            'Grain': 'G', 'Grain_number': 'G', 'Grain size': 'G',
            'Temperature': 'T', 'Temp': 'T', 'Temperature_C': 'T',
            'Time': 't', 'Time_h': 't', 'Hours': 't',
            'Sigma_phase': 'f_exp (%)', 'Sigma': 'f_exp (%)', 
            'Sigma_%': 'f_exp (%)', 'f_exp': 'f_exp (%)'
        }
        
        df_normalized = df.copy()
        new_columns = {}
        
        for col in df.columns:
            col_clean = str(col).strip()
            if col_clean in column_mapping:
                new_columns[col] = column_mapping[col_clean]
            else:
                new_columns[col] = col_clean
        
        df_normalized.columns = [new_columns[col] for col in df.columns]
        return df_normalized
    
    @staticmethod
    def validate_data(df):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö"""
        required_columns = ['G', 'T', 't', 'f_exp (%)']
        
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return False, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}"
        
        try:
            df['G'] = pd.to_numeric(df['G'], errors='coerce')
            df['T'] = pd.to_numeric(df['T'], errors='coerce')
            df['t'] = pd.to_numeric(df['t'], errors='coerce')
            df['f_exp (%)'] = pd.to_numeric(df['f_exp (%)'], errors='coerce')
        except Exception as e:
            return False, f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö: {e}"
        
        if df[required_columns].isna().any().any():
            return False, "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—É—Å—Ç—ã–µ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∞–Ω–Ω—ã—Ö"
        
        if (df['G'] < -3).any() or (df['G'] > 14).any():
            return False, "–ù–æ–º–µ—Ä –∑–µ—Ä–Ω–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç -3 –¥–æ 14"
        
        if (df['T'] < 500).any() or (df['T'] > 1000).any():
            st.warning("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –≤—ã—Ö–æ–¥—è—Ç –∑–∞ typical –¥–∏–∞–ø–∞–∑–æ–Ω 500-1000¬∞C")
        
        if (df['f_exp (%)'] < 0).any() or (df['f_exp (%)'] > 50).any():
            st.warning("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Å–∏–≥–º–∞-—Ñ–∞–∑—ã –≤—ã—Ö–æ–¥—è—Ç –∑–∞ typical –¥–∏–∞–ø–∞–∑–æ–Ω 0-50%")
        
        DataValidator.validate_time_range(df['t'])
        
        return True, "–î–∞–Ω–Ω—ã–µ –≤–∞–ª–∏–¥–Ω—ã"
    
    @staticmethod
    def validate_time_range(t_values):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –≤—Ä–µ–º–µ–Ω–∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏"""
        max_time = 500000
        if (t_values > max_time).any():
            st.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏ —Å–≤—ã—à–µ {max_time} —á–∞—Å–æ–≤")
        return True

class GrainSizeConverter:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –Ω–æ–º–µ—Ä–∞ –∑–µ—Ä–Ω–∞ –≤ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ –ì–û–°–¢ 5639-82"""
    
    GRAIN_DATA = {
        -3: {'area_mm2': 1.000, 'diameter_mm': 1.000, 'conditional_diameter_mm': 0.875, 'grains_per_mm2': 1.0},
        -2: {'area_mm2': 0.500, 'diameter_mm': 0.707, 'conditional_diameter_mm': 0.650, 'grains_per_mm2': 2.8},
        -1: {'area_mm2': 0.250, 'diameter_mm': 0.500, 'conditional_diameter_mm': 0.444, 'grains_per_mm2': 8.0},
        0:  {'area_mm2': 0.125, 'diameter_mm': 0.353, 'conditional_diameter_mm': 0.313, 'grains_per_mm2': 22.6},
        1:  {'area_mm2': 0.0625, 'diameter_mm': 0.250, 'conditional_diameter_mm': 0.222, 'grains_per_mm2': 64.0},
        2:  {'area_mm2': 0.0312, 'diameter_mm': 0.177, 'conditional_diameter_mm': 0.157, 'grains_per_mm2': 181.0},
        3:  {'area_mm2': 0.0156, 'diameter_mm': 0.125, 'conditional_diameter_mm': 0.111, 'grains_per_mm2': 512.0},
        4:  {'area_mm2': 0.00781, 'diameter_mm': 0.088, 'conditional_diameter_mm': 0.0783, 'grains_per_mm2': 1448.0},
        5:  {'area_mm2': 0.00390, 'diameter_mm': 0.062, 'conditional_diameter_mm': 0.0553, 'grains_per_mm2': 4096.0},
        6:  {'area_mm2': 0.00195, 'diameter_mm': 0.044, 'conditional_diameter_mm': 0.0391, 'grains_per_mm2': 11585.0},
        7:  {'area_mm2': 0.00098, 'diameter_mm': 0.031, 'conditional_diameter_mm': 0.0267, 'grains_per_mm2': 32768.0},
        8:  {'area_mm2': 0.00049, 'diameter_mm': 0.022, 'conditional_diameter_mm': 0.0196, 'grains_per_mm2': 92682.0},
        9:  {'area_mm2': 0.000244, 'diameter_mm': 0.015, 'conditional_diameter_mm': 0.0138, 'grains_per_mm2': 262144.0},
        10: {'area_mm2': 0.000122, 'diameter_mm': 0.011, 'conditional_diameter_mm': 0.0099, 'grains_per_mm2': 741485.0},
        11: {'area_mm2': 0.000061, 'diameter_mm': 0.0079, 'conditional_diameter_mm': 0.0069, 'grains_per_mm2': 2097152.0},
        12: {'area_mm2': 0.000030, 'diameter_mm': 0.0056, 'conditional_diameter_mm': 0.0049, 'grains_per_mm2': 5931008.0},
        13: {'area_mm2': 0.000015, 'diameter_mm': 0.0039, 'conditional_diameter_mm': 0.0032, 'grains_per_mm2': 16777216.0},
        14: {'area_mm2': 0.000008, 'diameter_mm': 0.0027, 'conditional_diameter_mm': 0.0027, 'grains_per_mm2': 47449064.0}
    }
    
    @classmethod
    def grain_number_to_area(cls, grain_number):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ –∑–µ—Ä–Ω–∞ –≤ —Å—Ä–µ–¥–Ω—é—é –ø–ª–æ—â–∞–¥—å —Å–µ—á–µ–Ω–∏—è (–º–º¬≤)"""
        data = cls.GRAIN_DATA.get(grain_number)
        if data:
            return data['area_mm2']
        else:
            numbers = sorted(cls.GRAIN_DATA.keys())
            if grain_number < numbers[0]:
                return cls.GRAIN_DATA[numbers[0]]['area_mm2']
            elif grain_number > numbers[-1]:
                return cls.GRAIN_DATA[numbers[-1]]['area_mm2']
            else:
                lower = max([n for n in numbers if n <= grain_number])
                upper = min([n for n in numbers if n >= grain_number])
                if lower == upper:
                    return cls.GRAIN_DATA[lower]['area_mm2']
                log_area_lower = np.log(cls.GRAIN_DATA[lower]['area_mm2'])
                log_area_upper = np.log(cls.GRAIN_DATA[upper]['area_mm2'])
                fraction = (grain_number - lower) / (upper - lower)
                log_area = log_area_lower + fraction * (log_area_upper - log_area_lower)
                return np.exp(log_area)
    
    @classmethod
    def grain_number_to_diameter(cls, grain_number, use_conditional=True):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ –∑–µ—Ä–Ω–∞ –≤ –¥–∏–∞–º–µ—Ç—Ä (–º–º)"""
        data = cls.GRAIN_DATA.get(grain_number)
        if data:
            return data['conditional_diameter_mm'] if use_conditional else data['diameter_mm']
        else:
            numbers = sorted(cls.GRAIN_DATA.keys())
            if grain_number < numbers[0]:
                return cls.GRAIN_DATA[numbers[0]]['conditional_diameter_mm'] if use_conditional else cls.GRAIN_DATA[numbers[0]]['diameter_mm']
            elif grain_number > numbers[-1]:
                return cls.GRAIN_DATA[numbers[-1]]['conditional_diameter_mm'] if use_conditional else cls.GRAIN_DATA[numbers[-1]]['diameter_mm']
            else:
                lower = max([n for n in numbers if n <= grain_number])
                upper = min([n for n in numbers if n >= grain_number])
                if lower == upper:
                    return cls.GRAIN_DATA[lower]['conditional_diameter_mm'] if use_conditional else cls.GRAIN_DATA[lower]['diameter_mm']
                diam_lower = cls.GRAIN_DATA[lower]['conditional_diameter_mm'] if use_conditional else cls.GRAIN_DATA[lower]['diameter_mm']
                diam_upper = cls.GRAIN_DATA[upper]['conditional_diameter_mm'] if use_conditional else cls.GRAIN_DATA[upper]['diameter_mm']
                fraction = (grain_number - lower) / (upper - lower)
                return diam_lower + fraction * (diam_upper - diam_lower)
    
    @classmethod
    def calculate_grain_boundary_density(cls, grain_number):
        """–†–∞—Å—á–µ—Ç –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –≥—Ä–∞–Ω–∏—Ü –∑–µ—Ä–µ–Ω (–º–º¬≤/–º–º¬≥)"""
        d = cls.grain_number_to_diameter(grain_number, use_conditional=True)
        Sv = 3.0 / (d / 2.0)
        return Sv
    
    @classmethod
    def calculate_activation_energy_factor(cls, grain_number):
        """–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–ª–∏—è–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –∑–µ—Ä–Ω–∞ –Ω–∞ —ç–Ω–µ—Ä–≥–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏"""
        ref_grain = 5
        Sv_ref = cls.calculate_grain_boundary_density(ref_grain)
        Sv_current = cls.calculate_grain_boundary_density(grain_number)
        return Sv_current / Sv_ref

class SigmaPhaseAnalyzer:
    def __init__(self):
        self.params = None
        self.R2 = None
        self.rmse = None
        self.mape = None
        self.model_type = None
        self.final_formula = ""
        
    def fit_model(self, data, model_type="avrami_saturation"):
        """–ü–æ–¥–≥–æ–Ω–∫–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            G = data['G'].values
            T = data['T'].values + 273.15
            t = data['t'].values
            f_exp = data['f_exp (%)'].values
            
            self.model_type = model_type
            
            if model_type == "avrami_saturation":
                success = self._fit_avrami_model(G, T, t, f_exp)
            elif model_type == "power_law":
                success = self._fit_power_law_model(G, T, t, f_exp)
            elif model_type == "logistic":
                success = self._fit_logistic_model(G, T, t, f_exp)
            elif model_type == "ensemble":
                success = self._fit_ensemble_model(G, T, t, f_exp)
            else:
                st.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")
                return False
                
            if success:
                self._generate_final_formula()
                
            return success
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ–Ω–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def _fit_avrami_model(self, G, T, t, f_exp):
        """–ú–æ–¥–µ–ª—å –ê–≤—Ä–∞–º–∏ —Å –Ω–∞—Å—ã—â–µ–Ω–∏–µ–º"""
        initial_guess = [8.0, 1e10, 200000, 1.0, 0.1]
        bounds = (
            [1.0, 1e5, 100000, 0.1, -1.0],
            [15.0, 1e15, 400000, 3.0, 1.0]
        )
        
        def model(params, G, T, t):
            f_max, K0, Q, n, alpha = params
            R = 8.314
            grain_effect = 1 + alpha * (G - 8)
            K = K0 * np.exp(-Q / (R * T)) * grain_effect
            return f_max * (1 - np.exp(-K * (t ** n)))
        
        self.params, _ = curve_fit(
            lambda x, f_max, K0, Q, n, alpha: model([f_max, K0, Q, n, alpha], G, T, t),
            np.arange(len(G)), f_exp,
            p0=initial_guess,
            bounds=bounds,
            maxfev=5000
        )
        
        f_pred = model(self.params, G, T, t)
        self.R2 = r2_score(f_exp, f_pred)
        self.rmse = np.sqrt(mean_squared_error(f_exp, f_pred))
        self.mape = np.mean(np.abs((f_exp - f_pred) / f_exp)) * 100
        return True
    
    def _fit_power_law_model(self, G, T, t, f_exp):
        """–°—Ç–µ–ø–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å"""
        initial_guess = [1.0, 0.1, -10000, 0.5, 0.01]
        bounds = (
            [0.1, -1.0, -50000, 0.1, -0.1],
            [10.0, 1.0, -1000, 2.0, 0.1]
        )
        
        def model(params, G, T, t):
            A, B, C, D, E = params
            R = 8.314
            temp_effect = np.exp(C / (R * T))
            time_effect = t ** D
            grain_effect = 1 + E * (G - 8)
            return A * temp_effect * time_effect * grain_effect + B
        
        self.params, _ = curve_fit(
            lambda x, A, B, C, D, E: model([A, B, C, D, E], G, T, t),
            np.arange(len(G)), f_exp,
            p0=initial_guess,
            bounds=bounds,
            maxfev=5000
        )
        
        f_pred = model(self.params, G, T, t)
        self.R2 = r2_score(f_exp, f_pred)
        self.rmse = np.sqrt(mean_squared_error(f_exp, f_pred))
        self.mape = np.mean(np.abs((f_exp - f_pred) / f_exp)) * 100
        return True
    
    def _fit_logistic_model(self, G, T, t, f_exp):
        """–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å"""
        initial_guess = [8.0, 1e-4, 1000, 0.1, -10000]
        bounds = (
            [1.0, 1e-8, 100, -1.0, -50000],
            [15.0, 1e-2, 10000, 1.0, -1000]
        )
        
        def model(params, G, T, t):
            f_max, k, t0, alpha, beta = params
            R = 8.314
            temp_factor = np.exp(beta / (R * T))
            grain_factor = 1 + alpha * (G - 8)
            rate = k * temp_factor * grain_factor
            return f_max / (1 + np.exp(-rate * (t - t0)))
        
        self.params, _ = curve_fit(
            lambda x, f_max, k, t0, alpha, beta: model([f_max, k, t0, alpha, beta], G, T, t),
            np.arange(len(G)), f_exp,
            p0=initial_guess,
            bounds=bounds,
            maxfev=5000
        )
        
        f_pred = model(self.params, G, T, t)
        self.R2 = r2_score(f_exp, f_pred)
        self.rmse = np.sqrt(mean_squared_error(f_exp, f_pred))
        self.mape = np.mean(np.abs((f_exp - f_pred) / f_exp)) * 100
        return True
    
    def _fit_ensemble_model(self, G, T, t, f_exp):
        """–ê–Ω—Å–∞–º–±–ª–µ–≤–∞—è –º–æ–¥–µ–ª—å"""
        initial_guess = [5.0, 1e8, 150000, 0.5, 0.1, 0.1, -20000]
        bounds = (
            [1.0, 1e5, 100000, 0.1, -1.0, 0.01, -50000],
            [15.0, 1e12, 300000, 2.0, 1.0, 1.0, -1000]
        )
        
        def model(params, G, T, t):
            f_max, K0, Q, n, alpha, w, beta = params
            R = 8.314
            
            # –ê–≤—Ä–∞–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
            grain_effect_avrami = 1 + alpha * (G - 8)
            K_avrami = K0 * np.exp(-Q / (R * T)) * grain_effect_avrami
            f_avrami = f_max * (1 - np.exp(-K_avrami * (t ** n)))
            
            # –°—Ç–µ–ø–µ–Ω–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
            temp_effect_power = np.exp(beta / (R * T))
            f_power = w * temp_effect_power * (t ** 0.5) * (1 + 0.05 * (G - 8))
            
            return f_avrami + f_power
        
        self.params, _ = curve_fit(
            lambda x, f_max, K0, Q, n, alpha, w, beta: model([f_max, K0, Q, n, alpha, w, beta], G, T, t),
            np.arange(len(G)), f_exp,
            p0=initial_guess,
            bounds=bounds,
            maxfev=10000
        )
        
        f_pred = model(self.params, G, T, t)
        self.R2 = r2_score(f_exp, f_pred)
        self.rmse = np.sqrt(mean_squared_error(f_exp, f_pred))
        self.mape = np.mean(np.abs((f_exp - f_pred) / f_exp)) * 100
        return True
    
    def _generate_final_formula(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–∏—Ç–∞–µ–º–æ–π —Ñ–æ—Ä–º—É–ª—ã –º–æ–¥–µ–ª–∏"""
        if self.params is None:
            self.final_formula = "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞"
            return
            
        if self.model_type == "avrami_saturation":
            f_max, K0, Q, n, alpha = self.params
            self.final_formula = f"""
**–ú–æ–¥–µ–ª—å –ê–≤—Ä–∞–º–∏ —Å –Ω–∞—Å—ã—â–µ–Ω–∏–µ–º:**
f(G, T, t) = {f_max:.3f} √ó [1 - exp(-K √ó t^{n:.3f})]
K = {K0:.3e} √ó exp(-{Q/1000:.1f} –∫–î–∂/–º–æ–ª—å / (R √ó T)) √ó [1 + {alpha:.3f} √ó (G - 8)]
"""
        elif self.model_type == "power_law":
            A, B, C, D, E = self.params
            self.final_formula = f"""
**–°—Ç–µ–ø–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å:**
f(G, T, t) = {A:.3f} √ó exp({C:.0f} / (R √ó T)) √ó t^{D:.3f} √ó [1 + {E:.3f} √ó (G - 8)] + {B:.3f}
"""
        elif self.model_type == "logistic":
            f_max, k, t0, alpha, beta = self.params
            self.final_formula = f"""
**–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å:**
f(G, T, t) = {f_max:.3f} / [1 + exp(-k √ó (t - {t0:.0f}))]
k = {k:.3e} √ó exp({beta:.0f} / (R √ó T)) √ó [1 + {alpha:.3f} √ó (G - 8)]
"""
        elif self.model_type == "ensemble":
            f_max, K0, Q, n, alpha, w, beta = self.params
            self.final_formula = f"""
**–ê–Ω—Å–∞–º–±–ª–µ–≤–∞—è –º–æ–¥–µ–ª—å:**
f(G, T, t) = f_avrami + f_power

f_avrami = {f_max:.3f} √ó [1 - exp(-K_avrami √ó t^{n:.3f})]
K_avrami = {K0:.3e} √ó exp(-{Q/1000:.1f} –∫–î–∂/–º–æ–ª—å / (R √ó T)) √ó [1 + {alpha:.3f} √ó (G - 8)]

f_power = {w:.3f} √ó exp({beta:.0f} / (R √ó T)) √ó t^0.5 √ó [1 + 0.05 √ó (G - 8)]
"""
        
        self.final_formula += "\n**R = 8.314 –î–∂/(–º–æ–ª—å¬∑–ö) - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –≥–∞–∑–æ–≤–∞—è –ø–æ—Å—Ç–æ—è–Ω–Ω–∞—è**\n**T - —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤ –ö–µ–ª—å–≤–∏–Ω–∞—Ö (T[¬∞C] + 273.15)**"
    
    def predict_temperature(self, G, sigma_percent, t):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã"""
        if self.params is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")
        
        sigma = sigma_percent
        
        # –ë–∏—Å–µ–∫—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
        T_min, T_max = 500, 900
        
        for i in range(100):
            T_mid = (T_min + T_max) / 2
            f_pred = self._evaluate_model(G, T_mid, t)
            
            if abs(f_pred - sigma) < 1.0:
                return T_mid
            
            if f_pred < sigma:
                T_min = T_mid
            else:
                T_max = T_mid
        
        return (T_min + T_max) / 2
    
    def _evaluate_model(self, G, T, t):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        if self.params is None:
            return 0.0
            
        T_kelvin = T + 273.15
        
        if self.model_type == "avrami_saturation":
            f_max, K0, Q, n, alpha = self.params
            R = 8.314
            grain_effect = 1 + alpha * (G - 8)
            K = K0 * np.exp(-Q / (R * T_kelvin)) * grain_effect
            return f_max * (1 - np.exp(-K * (t ** n)))
        
        elif self.model_type == "power_law":
            A, B, C, D, E = self.params
            R = 8.314
            temp_effect = np.exp(C / (R * T_kelvin))
            time_effect = t ** D
            grain_effect = 1 + E * (G - 8)
            return A * temp_effect * time_effect * grain_effect + B
        
        elif self.model_type == "logistic":
            f_max, k, t0, alpha, beta = self.params
            R = 8.314
            temp_factor = np.exp(beta / (R * T_kelvin))
            grain_factor = 1 + alpha * (G - 8)
            rate = k * temp_factor * grain_factor
            return f_max / (1 + np.exp(-rate * (t - t0)))
        
        elif self.model_type == "ensemble":
            f_max, K0, Q, n, alpha, w, beta = self.params
            R = 8.314
            
            grain_effect_avrami = 1 + alpha * (G - 8)
            K_avrami = K0 * np.exp(-Q / (R * T_kelvin)) * grain_effect_avrami
            f_avrami = f_max * (1 - np.exp(-K_avrami * (t ** n)))
            
            temp_effect_power = np.exp(beta / (R * T_kelvin))
            f_power = w * temp_effect_power * (t ** 0.5) * (1 + 0.05 * (G - 8))
            
            return f_avrami + f_power
        
        return 0.0
    
    def calculate_validation_metrics(self, data):
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        if self.params is None:
            return None
        
        G = data['G'].values
        T = data['T'].values
        t = data['t'].values
        f_exp = data['f_exp (%)'].values
        
        f_pred = np.array([self._evaluate_model(g, temp, time) for g, temp, time in zip(G, T, t)])
        
        residuals = f_pred - f_exp
        relative_errors = (residuals / f_exp) * 100
        
        valid_mask = np.isfinite(relative_errors) & (f_exp > 0.1)
        f_exp_valid = f_exp[valid_mask]
        f_pred_valid = f_pred[valid_mask]
        residuals_valid = residuals[valid_mask]
        relative_errors_valid = relative_errors[valid_mask]
        
        if len(f_exp_valid) == 0:
            return None
            
        mae = np.mean(np.abs(residuals_valid))
        rmse = np.sqrt(mean_squared_error(f_exp_valid, f_pred_valid))
        mape = np.mean(np.abs(relative_errors_valid))
        r2 = r2_score(f_exp_valid, f_pred_valid)
        
        validation_results = {
            'data': data.copy(),
            'predictions': f_pred,
            'residuals': residuals,
            'relative_errors': relative_errors,
            'metrics': {
                'MAE': mae,
                'RMSE': rmse,
                'MAPE': mape,
                'R2': r2
            }
        }
        
        return validation_results

def read_uploaded_file(uploaded_file):
    """–ß—Ç–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    try:
        if uploaded_file.name.endswith('.csv'):
            try:
                data = pd.read_csv(uploaded_file, decimal=',', encoding='utf-8')
            except:
                try:
                    data = pd.read_csv(uploaded_file, decimal=',', encoding='cp1251')
                except:
                    data = pd.read_csv(uploaded_file, decimal='.', encoding='utf-8')
        else:
            try:
                if uploaded_file.name.endswith('.xlsx'):
                    data = pd.read_excel(uploaded_file, engine='openpyxl')
                else:
                    data = pd.read_excel(uploaded_file, engine='xlrd')
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Excel —Ñ–∞–π–ª–∞: {str(e)}")
                return None
        
        return data
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}")
        return None

def main():
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = None
    if 'current_data' not in st.session_state:
        st.session_state.current_data = None
    if 'validation_results' not in st.session_state:
        st.session_state.validation_results = None
    if 'excluded_points' not in st.session_state:
        st.session_state.excluded_points = set()
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = "ensemble"
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∫–ª–∞–¥–æ–∫
    tab1, tab2, tab3 = st.tabs(["üìä –î–∞–Ω–Ω—ã–µ –∏ –º–æ–¥–µ–ª—å", "üßÆ –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä", "üìà –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"])
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
    st.sidebar.header("üéØ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_type = st.sidebar.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å",
        ["avrami_saturation", "power_law", "logistic", "ensemble"],
        format_func=lambda x: {
            "avrami_saturation": "–ê–≤—Ä–∞–º–∏ —Å –Ω–∞—Å—ã—â–µ–Ω–∏–µ–º",
            "power_law": "–°—Ç–µ–ø–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å",
            "logistic": "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å", 
            "ensemble": "–ê–Ω—Å–∞–º–±–ª–µ–≤–∞—è –º–æ–¥–µ–ª—å"
        }[x],
        key="model_selector"
    )
    
    # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
    sample_data = pd.DataFrame({
        'G': [8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],
        'T': [600, 600, 600, 600, 650, 650, 650, 650, 600, 600, 600, 600, 650, 650, 650, 650, 600, 600, 600, 600, 650, 650, 650, 650, 700, 700],
        't': [2000, 4000, 6000, 8000, 2000, 4000, 6000, 8000, 2000, 4000, 6000, 8000, 2000, 4000, 6000, 8000, 2000, 4000, 6000, 8000, 2000, 4000, 6000, 8000, 2000, 4000],
        'f_exp (%)': [1.76, 0.68, 0.94, 1.09, 0.67, 1.2, 1.48, 1.13, 0.87, 1.28, 2.83, 3.25, 1.88, 2.29, 3.25, 2.89, 1.261, 2.04, 2.38, 3.3, 3.2, 4.26, 5.069, 5.41, 3.3, 5.0]
    })
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    st.sidebar.header("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    
    uploaded_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏",
        type=['csv', 'xlsx', 'xls']
    )
    
    if uploaded_file is not None:
        data = read_uploaded_file(uploaded_file)
        if data is not None:
            data = DataValidator.normalize_column_names(data)
            is_valid, message = DataValidator.validate_data(data)
            if is_valid:
                data['f_exp (%)'] = data['f_exp (%)'].round(3)
                st.session_state.current_data = data
                st.sidebar.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
    
    if st.session_state.current_data is None:
        st.session_state.current_data = sample_data

    # –í–ö–õ–ê–î–ö–ê 1: –î–∞–Ω–Ω—ã–µ –∏ –º–æ–¥–µ–ª—å
    with tab1:
        st.header("üìä –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏")
        
        st.info("üí° **–°–Ω–∏–º–∏—Ç–µ –≥–∞–ª–æ—á–∫–∏ —Å —Ç–æ—á–µ–∫, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ç–∏—Ç–µ –∏—Å–∫–ª—é—á–∏—Ç—å –∏–∑ –∞–Ω–∞–ª–∏–∑–∞**")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö —Å —á–µ–∫–±–æ–∫—Å–∞–º–∏
        display_data = st.session_state.current_data.copy()
        display_data['‚Ññ'] = range(1, len(display_data) + 1)
        display_data['–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å'] = [i not in st.session_state.excluded_points for i in range(len(display_data))]
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —á–µ–∫–±–æ–∫—Å–∞–º–∏
        edited_df = st.data_editor(
            display_data,
            column_config={
                "‚Ññ": st.column_config.NumberColumn(width="small"),
                "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å": st.column_config.CheckboxColumn(
                    width="small",
                    help="–°–Ω–∏–º–∏—Ç–µ –≥–∞–ª–æ—á–∫—É —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å —Ç–æ—á–∫—É"
                ),
                "G": st.column_config.NumberColumn(width="small"),
                "T": st.column_config.NumberColumn(width="small"),
                "t": st.column_config.NumberColumn(width="small"),
                "f_exp (%)": st.column_config.NumberColumn(format="%.3f", width="small")
            },
            column_order=["‚Ññ", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å", "G", "T", "t", "f_exp (%)"],
            use_container_width=True,
            height=400
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫
        new_excluded = set()
        for i, used in enumerate(edited_df['–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å']):
            if not used:
                new_excluded.add(i)
        
        if new_excluded != st.session_state.excluded_points:
            st.session_state.excluded_points = new_excluded
            st.session_state.analyzer = None
            st.session_state.validation_results = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total = len(display_data)
        excluded = len(st.session_state.excluded_points)
        included = total - excluded
        
        col1, col2, col3 = st.columns(3)
        col1.metric("–í—Å–µ–≥–æ —Ç–æ—á–µ–∫", total)

        
            
